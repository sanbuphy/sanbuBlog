---
title: 1-深度学习与计算机视觉历史
---

待补完，之后会优先放在github

# 一、课程介绍

- 课程名称：EECS 498007-598005，专注于深度学习在计算机视觉领域的应用。
- 讲师：Justin Johnson，密歇根大学助理教授，该课程是他在该校首次开设。
- 课程目标：探索如何利用深度学习技术处理、感知和推理视觉数据。

- 课程将专注于计算机视觉、机器学习和深度学习的交叉领域。
- 除了学习这些领域的基本概念，还将讨论最新的研究成果和技术。

- 定义：计算机视觉是构建能够处理、感知并推理视觉数据的人工系统的研究领域。
- 应用范围：可以包括图像、视频、医学扫描等任何类型的连续值信号。
- 重要性：由于视觉数据无处不在，且数量庞大，因此开发能够自动处理这些数据的系统变得至关重要。

# 二、计算机视觉的重要性和发展

- 统计数据：例如Instagram每天上传约1亿张照片和视频，YouTube每天上传约300小时视频。
- 技术发展：随着视觉传感器数量的增加，以及自动驾驶车辆、增强现实/虚拟现实、无人机等新兴技术的出现，计算机视觉的作用愈发凸显。

# 三、人工智能领域的概况

- 学习：构建能够从数据和经验中学习的系统。
- 深度学习：机器学习的一个子集，使用具有多个层次的层次化学习算法，受哺乳动物大脑结构的启发。
- 人工智能：构建能够执行人们通常执行的任务的计算机系统。
- 子领域：包括计算机视觉、机器学习等，本课程将聚焦于这些子领域的交叉部分。

# 四、历史背景

## 早期探索

- **Hubel和Wiesel的研究**：1963年，通过在猫脑中插入电极，研究了视觉皮层的神经元如何响应不同的视觉刺激，特别是对边缘的响应，为后续计算机视觉算法的发展奠定了基础。

## 计算机视觉的诞生

- **Larry Roberts的工作**：被认为是计算机视觉领域的第一个博士研究工作，他的工作集中在图像的边缘检测和3D几何理解上。

## 早期的乐观与挑战

- **MIT的夏季计算机视觉项目**：Seymour Papert在1966年提出的项目，目标是在夏季通过几名本科生的工作构建视觉系统的大部分，但最终未能实现这一雄心勃勃的目标。

## David Marr的理论贡献

- **视觉表示的阶段**：1970年代，David Marr提出了视觉信息处理的阶段理论，包括从原始图像到2D边缘提取，再到3D模型构建的过程。

## 1980年代的技术进步

- **数字相机和计算能力**：技术的进步使得计算机视觉研究可以处理更加现实的图像数据。

## 1990年代的对象识别

- **对象分组**：研究者开始尝试通过将图像分割成有意义的块来识别对象，而不是仅仅依赖边缘匹配。

## 2000年代的识别技术

- **SIFT算法**：David Lowe在1999年提出的算法，通过关键点匹配进行图像识别，强调了特征的不变性。
- **Viola-Jones算法**：2001年提出的面部识别算法，是机器学习在计算机视觉中的早期成功应用之一。

## 数据集的影响

- **Pascal视觉对象挑战**：通过互联网下载和标记图像，为机器学习算法提供了训练数据。
- **ImageNet数据集**：引入了大规模数据集和众包标注，对计算机视觉领域产生了深远影响。

## 深度学习的突破

- **AlexNet模型**：2012年在ImageNet竞赛中取得压倒性胜利，标志着深度学习在计算机视觉领域的突破。

# 五、深度学习的历史和发展

## 早期的探索与挑战

- **感知器**：1958年提出，作为早期的机器学习模型，能够对简单数据进行分类。
- **Minsky和Papert的批评**：1969年，他们的书籍《Perceptrons》指出了感知器的局限性，特别是它无法学习XOR这样的非线性问题，这导致了对神经网络研究的暂时性减退。

## 深度学习的潜伏与再生

- **Neocognitron**：1980年，Fukushima提出了Neocognitron模型，灵感来源于Hubel和Wiesel的视觉皮层研究，这是卷积神经网络（CNN）的前身。
- **反向传播算法**：1986年，Rumelhart, Hinton, Williams提出了反向传播算法，使得多层神经网络的训练成为可能。

## 卷积神经网络的诞生

- **LeCun等人的工作**：1998年，提出了卷积神经网络（CNN），并在手写数字识别上取得了突破性进展。

## 商业应用与数据集的重要性

- **商业化**：90年代末到2000年代初，CNN开始在商业领域得到应用，如用于处理美国支票上的文字识别。
- **Pascal VOC挑战**：推动了数据集的构建和机器学习在图像识别上的应用。

## ImageNet竞赛与深度学习的突破

- **ImageNet竞赛**：自2010年起，ImageNet大规模视觉识别挑战赛成为检验算法性能的重要平台。
- **AlexNet**：2012年，AlexNet在ImageNet竞赛中取得压倒性胜利，标志着深度学习在计算机视觉领域的突破。

## 算法、数据与计算能力的结合

- **算法发展**：深度学习算法的不断优化和创新。
- **数据获取**：互联网和众包技术的发展使得大量标记数据的获取成为可能。
- **计算能力**：特别是GPU的并行计算能力，为深度学习模型的训练提供了强大的硬件支持。

## 深度学习的普及与应用

- **技术普及**：从2012年起，深度学习技术在计算机视觉以及其他领域迅速普及。
- **应用广泛**：深度学习被应用于图像分类、目标检测、语音识别、自然语言处理等多种任务。

## 学术认可与未来展望

- **图灵奖**：2018年，深度学习领域的三位先驱Bengio, Hinton, LeCun获得图灵奖，肯定了他们在该领域的贡献。

# 六、课程政策和资源

- 课程将使用Piazza进行主要的沟通和问题讨论。
- 课程资料将通过课程网站提供，包括讲义、时间表、作业链接和讲座视频。
- 将使用Canvas提交作业。

- 课程主要由六个编程作业组成，涵盖Python、PyTorch和Google Colab的使用。
- 包括期中和期末考试，但没有课程项目。
- 作业延期政策：学生有免费的延期天数，逾期后将自动扣除。

- 强调理解基本概念，鼓励学生从零开始编写代码，而不是依赖现有的开源实现。
- 实际操作中会使用PyTorch和TensorFlow等现代工具，但在学生掌握了基本原理之后。

- 前半部分课程将专注于基础，包括不同类型的神经网络的实现细节。
- 后半部分将更多地关注应用和新兴研究主题，如目标检测、图像分割、3D视觉、视频处理、注意力机制、变换器、视觉与语言结合、生成模型等。
