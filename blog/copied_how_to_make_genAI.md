---
title: 没有核心训练团队,如何研发生成式模型?(内容转载)
date: 2024-11-23
---

最近看到这篇文章,个人觉得完美描述了在生成式AI的年代,普通团队(没有核心训练infra和细分分工的团队)如何作出好的模型产出,

从道和术的角度，概括了训练出好的生成式模型，其所需的方法.

原作者： <https://zhuanlan.zhihu.com/p/715712057>

<!--truncate-->

```
### 核心方法论
1. **问题转化**：
   - 将大模型训练拆解为 **三个搜索问题**：
     - **模型配置搜索**：在给定资源下寻找合适的模型架构。
     - **训练超参搜索**：优化超参数以降低 loss 或提高下游任务表现。
     - **数据约束搜索**：调整数据使其更适合模型训练。
   - 这种转化将复杂的问题规整为工程领域熟悉的优化问题。

2. **搜索优化方向**：
   - **跑得快**：
     1. **Scaling law**：借助小模型快速实验并推测大模型行为。
     2. **提升MFU**：优化训练框架，使GPU/TPU的计算资源利用率更高。
     3. **任务流优化**：确保硬件资源始终被充分使用。
   - **搜得少**：
     1. **先验知识**：基于论文、社区经验设置合理的初值。
     2. **明确瓶颈**：通过 baseline 和 benchmark 找到最需要优化的环节。

---

### 工程创新点
1. **工程师优势最大化**：
   - 虽然团队缺少研究背景，但工程师拥有丰富的优化经验，善于快速迭代和找到局部最优解。
   - 通过高效的工程实践将大模型的研究问题转化为工程问题。

2. **资源利用策略**：
   - **分层实验**：利用小模型实验的低成本性，缩小搜索空间。
   - **集群优化**：通过任务队列管理和框架改进，确保 GPU 不浪费空转时间。

3. **对标与验证**：
   - 持续与公开研究成果对比，确保训练方法是主流且有效的。
   - 增加 benchmark 数据集，精确验证改进效果。

---

### 经验总结
1. **兵法思维**：
   - 通过工程优化将问题拉到团队擅长的维度。
   - 在这个维度上利用经验积累实现突破，即“傻子兵法”的智慧。

2. **实践验证**：
   - 实践证明了这些工程方法的有效性，最终找到了一套性价比高的解决方案（局部最优点）。

3. **心态转变**：
   - 通过明确问题的常规性，增强了面对困难的信心和执行力。

---
```

```
今年，我们内部对从 pretrain 到 sft 的整个大模型训练流程进行了翻新，模型能力上也有了比较明显的提升，我也在这个过程中对训练有了更深入的理解，在这里分享一下，也算是对自己工作以来最累的一段时光的记录。

从方法论的角度，我认为这次翻新的核心在于，将问题转化为我们擅长的问题。

一般认为，大模型的训练团队应该由这么 2 波人组成：

一波是像 Ilya Suskever 或者 John Schulman 这样的研究人员来提供研究目标与实验方案；
另一波是类似 Greg Brockman 这样的工程师，提供相对稳定的集群，高速的训练框架与推理服务（我不确定 Greg 是干这个的... 但是就是那么个意思吧~）
这两拨人的工作相对解耦，研究人员开开心心做实验，工程师认认真真做优化，从而训出了像 GPT4 这样轰动世界的模型。

但是我们不具备这样的条件：我们的团队中几乎没有研究人员（甚至没有一个 phd），但是有很多经验丰富的工程师。那么扪心自问，我们凭什么能训出来还不错的模型呢？

如果我们转换思维，在 OpenAI 验证了大模型的可行性后。我们可以将大模型的训练问题转变为 3 个搜索问题：

给定训练与推理资源，搜索合适的模型配置；
给定模型配置，搜索训练超参，使其有更低的 next token loss（或在下游 benchmark 上表现出色）；
给定数据，搜索某种数据约束，使其更适合模型训练。
而搜索问题，是很传统的工程问题，只需要考虑：

如何在单位时间内搜更多次，即每次搜索跑得快一些；
如何建立合适的先验，以设置初值与剪枝，即搜得少一点。
对于跑得快，在大模型这里有这样的 3 种优化手段：

相信 scaling law，先在小模型上做大量的实验；
优化训练框架，提升 MFU；
优化任务提交流程，保证卡永远在跑着。
对于搜的少，则采用这样的方法：

通过看论文和博文，知道大家都是咋做的，来设置初值；
通过找到客观的 baseline 以及增加 benchmark，明确差距/瓶颈，针对性提升，来减少实验量。
当我们这样展开问题后，训练大模型这个任务，就变得比较常规了，也就有了直面困难的信心。剩下的事情也就是老老实实去看论文、跑实验、优化框架和提升集群利用率了~

幸运的是，近几个月我们的实践也验证了这套分析的可行性，采用这样的工程手段，是可以搜到一个相当不错的局部最优点的。这段经历让我积累了一条很有趣的经验：我们尝嘲笑说，傻子最擅长的事情是把别人拉到和他一个水平，然后利用他在那个水平丰富的经验击败对手，但是当自己是傻子的时候，也许这就是兵法~
```
